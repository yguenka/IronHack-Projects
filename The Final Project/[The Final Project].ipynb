{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Câncer de Pele\n",
    "Fontes: \n",
    "https://www.kaggle.com/fanconic/skin-cancer-malignant-vs-benign\n",
    "\n",
    "https://saude.gov.br/saude-de-a-z/cancer-de-pele\n",
    "\n",
    "https://www.sbd.org.br/\n",
    "\n",
    "https://www.inca.gov.br/tipos-de-cancer/cancer-de-pele-nao-melanoma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T14:42:03.296371Z",
     "start_time": "2020-05-19T14:42:03.285704Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Para o treino, foram utilizados 400 imagens no total, sendo 200 imagens de manchas benígnas e 200 imagens de manchas malígnas para que possa balancear o DataFrame.\n",
    "\n",
    "Já no caso do teste, foram utilizadas 85 imagens de manchas benígnas e 15 imagens de manchas malígnas, já que na campanha de 2018 realizado no Dia Nacional de Combate ao Câncer de Pele foram constatados que 15% dos exames realizados possuíam câncer de pele.\n",
    "\n",
    "Fonte: http://sbd.tempsite.ws/capele/gestao/incidencia.asp?uf=NULL&cidade=NULL&servico=NULL&campanha=17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T20:40:01.164889Z",
     "start_time": "2020-05-18T20:31:16.627971Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "real_list=[]\n",
    "path = 'data/train/benign'\n",
    "path_test = os.listdir(path=f'{path}')\n",
    "for item in range(0,200):\n",
    "    foto = path_test[item]\n",
    "    img=mpimg.imread(f'{path}/{foto}')\n",
    "    scaled = img / 255\n",
    "    data = scaled.reshape(scaled.shape[0] * scaled.shape[1] * scaled.shape[2])\n",
    "    real_list.append(data)\n",
    "train_b = pd.DataFrame(real_list)\n",
    "\n",
    "real_list=[]\n",
    "path = 'data/train/malignant'\n",
    "path_test = os.listdir(path=f'{path}')\n",
    "for item in range(0,200):\n",
    "    foto = path_test[item]\n",
    "    img=mpimg.imread(f'{path}/{foto}')\n",
    "    scaled = img / 255\n",
    "    data = scaled.reshape(scaled.shape[0] * scaled.shape[1] * scaled.shape[2])\n",
    "    real_list.append(data)\n",
    "train_m = pd.DataFrame(real_list)\n",
    "\n",
    "train = train_b.append(train_m, ignore_index=True)\n",
    "\n",
    "train['target'] = 0\n",
    "for item in range(0,400):\n",
    "    if item < 200:\n",
    "        train['target'][item] = 0\n",
    "    else: \n",
    "        train['target'][item] = 1\n",
    "        \n",
    "#train.to_csv('data_train.csv', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T14:12:07.671898Z",
     "start_time": "2020-05-19T14:11:15.261415Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "real_list=[]\n",
    "path = 'data/test/benign'\n",
    "path_test = os.listdir(path=f'{path}')\n",
    "for item in range(0,85):\n",
    "    foto = path_test[item]\n",
    "    img=mpimg.imread(f'{path}/{foto}')\n",
    "    scaled = img / 255\n",
    "    data = scaled.reshape(scaled.shape[0] * scaled.shape[1] * scaled.shape[2])\n",
    "    real_list.append(data)\n",
    "test_b = pd.DataFrame(real_list)\n",
    "\n",
    "real_list=[]\n",
    "path = 'data/test/malignant'\n",
    "path_test = os.listdir(path=f'{path}')\n",
    "for item in range(0,15):\n",
    "    foto = path_test[item]\n",
    "    img=mpimg.imread(f'{path}/{foto}')\n",
    "    scaled = img / 255\n",
    "    data = scaled.reshape(scaled.shape[0] * scaled.shape[1] * scaled.shape[2])\n",
    "    real_list.append(data)\n",
    "test_m = pd.DataFrame(real_list)\n",
    "\n",
    "test = test_b.append(test_m, ignore_index=True)\n",
    "\n",
    "test['target'] = 0\n",
    "for item in range(0,100):\n",
    "    if item < 85:\n",
    "        test['target'][item] = 0\n",
    "    else: \n",
    "        test['target'][item] = 1\n",
    "        \n",
    "#test.to_csv('data_test.csv', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "Diminuir a quantidade de colunas mantendo 95% da qualidade dos dados, pois utilizar redes neurais com muitas colunas, a análise demora muito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T14:26:47.965772Z",
     "start_time": "2020-05-19T14:26:40.605034Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['target'])\n",
    "y_train = train['target']\n",
    "X_test = test.drop(columns=['target'])\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T14:26:49.339124Z",
     "start_time": "2020-05-19T14:26:47.968765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>150518</th>\n",
       "      <th>150519</th>\n",
       "      <th>150520</th>\n",
       "      <th>150521</th>\n",
       "      <th>150522</th>\n",
       "      <th>150523</th>\n",
       "      <th>150524</th>\n",
       "      <th>150525</th>\n",
       "      <th>150526</th>\n",
       "      <th>150527</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.886275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.592157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.435294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.443137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.407843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.701961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.517647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.031373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.050980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.545098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 150528 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.870588  0.686275  0.756863  0.874510  0.694118  0.737255  0.874510   \n",
       "1    0.831373  0.470588  0.521569  0.835294  0.474510  0.517647  0.839216   \n",
       "2    0.823529  0.501961  0.549020  0.815686  0.513725  0.552941  0.835294   \n",
       "3    0.631373  0.462745  0.490196  0.631373  0.466667  0.482353  0.631373   \n",
       "4    0.917647  0.623529  0.705882  0.921569  0.635294  0.713725  0.905882   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  0.807843  0.576471  0.552941  0.827451  0.576471  0.568627  0.835294   \n",
       "396  0.058824  0.035294  0.043137  0.062745  0.023529  0.027451  0.066667   \n",
       "397  0.094118  0.047059  0.062745  0.117647  0.058824  0.086275  0.141176   \n",
       "398  0.796078  0.705882  0.737255  0.780392  0.690196  0.721569  0.784314   \n",
       "399  0.196078  0.129412  0.152941  0.231373  0.156863  0.180392  0.274510   \n",
       "\n",
       "            7         8         9  ...    150518    150519    150520  \\\n",
       "0    0.694118  0.745098  0.886275  ...  0.541176  0.749020  0.556863   \n",
       "1    0.478431  0.521569  0.854902  ...  0.458824  0.752941  0.439216   \n",
       "2    0.537255  0.576471  0.843137  ...  0.450980  0.709804  0.482353   \n",
       "3    0.462745  0.490196  0.631373  ...  0.419608  0.572549  0.396078   \n",
       "4    0.623529  0.701961  0.909804  ...  0.709804  0.901961  0.678431   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "395  0.564706  0.537255  0.823529  ...  0.498039  0.800000  0.576471   \n",
       "396  0.027451  0.023529  0.066667  ...  0.058824  0.066667  0.027451   \n",
       "397  0.070588  0.117647  0.168627  ...  0.070588  0.078431  0.043137   \n",
       "398  0.694118  0.725490  0.796078  ...  0.568627  0.682353  0.584314   \n",
       "399  0.192157  0.219608  0.313725  ...  0.109804  0.098039  0.047059   \n",
       "\n",
       "       150521    150522    150523    150524    150525    150526    150527  \n",
       "0    0.541176  0.764706  0.560784  0.568627  0.776471  0.568627  0.592157  \n",
       "1    0.443137  0.749020  0.435294  0.431373  0.764706  0.447059  0.435294  \n",
       "2    0.435294  0.713725  0.486275  0.431373  0.721569  0.486275  0.443137  \n",
       "3    0.423529  0.564706  0.388235  0.415686  0.556863  0.380392  0.407843  \n",
       "4    0.705882  0.909804  0.678431  0.701961  0.901961  0.678431  0.701961  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "395  0.501961  0.796078  0.576471  0.509804  0.788235  0.580392  0.517647  \n",
       "396  0.058824  0.062745  0.019608  0.050980  0.054902  0.019608  0.031373  \n",
       "397  0.054902  0.074510  0.031373  0.047059  0.074510  0.023529  0.050980  \n",
       "398  0.556863  0.690196  0.584314  0.549020  0.686275  0.580392  0.545098  \n",
       "399  0.074510  0.082353  0.039216  0.062745  0.086275  0.043137  0.066667  \n",
       "\n",
       "[400 rows x 150528 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:00:49.884457Z",
     "start_time": "2020-05-18T17:52:58.458387Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent = []\n",
    "components = []\n",
    "\n",
    "for i in range (5,100, 5):\n",
    "    pca = PCA(i/100)\n",
    "    percent.append(i/100)\n",
    "    components.append(len(pca.fit_transform(X_train)[0]))\n",
    "    \n",
    "plt.plot(components, percent)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:02:28.265510Z",
     "start_time": "2020-05-18T18:02:03.855910Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:02:28.273492Z",
     "start_time": "2020-05-18T18:02:28.267505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 84)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #Ao manter 95% da qualidade dos dados, foi possível reduzir para 84 colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "Foi utilizado uma Rede Neural Convolucional, onde não há influencias entre os dados. Caso tenha influência, ele pode dar puxar os dados da foto anterior e classificar sofrendo influência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:04:18.000623Z",
     "start_time": "2020-05-18T18:04:17.897888Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(units=12, input_dim=84, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "\n",
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "\n",
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 12, input_dim=84, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:04:22.557926Z",
     "start_time": "2020-05-18T18:04:18.131272Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "400/400 [==============================] - 0s 531us/step - loss: 0.6925 - accuracy: 0.6150\n",
      "Epoch 2/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.6892 - accuracy: 0.7250\n",
      "Epoch 3/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.6768 - accuracy: 0.7900\n",
      "Epoch 4/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.6340 - accuracy: 0.8025\n",
      "Epoch 5/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.5494 - accuracy: 0.8075\n",
      "Epoch 6/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.4548 - accuracy: 0.8125\n",
      "Epoch 7/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.3902 - accuracy: 0.8250\n",
      "Epoch 8/150\n",
      "400/400 [==============================] - 0s 56us/step - loss: 0.3528 - accuracy: 0.8375\n",
      "Epoch 9/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.3272 - accuracy: 0.8450\n",
      "Epoch 10/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.3069 - accuracy: 0.8675\n",
      "Epoch 11/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.2901 - accuracy: 0.8825\n",
      "Epoch 12/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.2736 - accuracy: 0.8850\n",
      "Epoch 13/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.2575 - accuracy: 0.8950\n",
      "Epoch 14/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.2432 - accuracy: 0.8975\n",
      "Epoch 15/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.2292 - accuracy: 0.9025\n",
      "Epoch 16/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.2157 - accuracy: 0.9075\n",
      "Epoch 17/150\n",
      "400/400 [==============================] - 0s 58us/step - loss: 0.2022 - accuracy: 0.9225\n",
      "Epoch 18/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.1889 - accuracy: 0.9350\n",
      "Epoch 19/150\n",
      "400/400 [==============================] - 0s 56us/step - loss: 0.1768 - accuracy: 0.9400\n",
      "Epoch 20/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.1651 - accuracy: 0.9500\n",
      "Epoch 21/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.1550 - accuracy: 0.9525\n",
      "Epoch 22/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.1462 - accuracy: 0.9525\n",
      "Epoch 23/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.1356 - accuracy: 0.9600\n",
      "Epoch 24/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.1256 - accuracy: 0.9625\n",
      "Epoch 25/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.1179 - accuracy: 0.9725\n",
      "Epoch 26/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.1098 - accuracy: 0.9750\n",
      "Epoch 27/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.1027 - accuracy: 0.9800\n",
      "Epoch 28/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0959 - accuracy: 0.9825\n",
      "Epoch 29/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0898 - accuracy: 0.9825\n",
      "Epoch 30/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0831 - accuracy: 0.9825\n",
      "Epoch 31/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0765 - accuracy: 0.9850\n",
      "Epoch 32/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0701 - accuracy: 0.9850\n",
      "Epoch 33/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0647 - accuracy: 0.9850\n",
      "Epoch 34/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0598 - accuracy: 0.9900\n",
      "Epoch 35/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0539 - accuracy: 0.9900\n",
      "Epoch 36/150\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.0499 - accuracy: 0.9975\n",
      "Epoch 37/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0452 - accuracy: 0.9975\n",
      "Epoch 38/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0413 - accuracy: 0.9975\n",
      "Epoch 39/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0387 - accuracy: 0.9975\n",
      "Epoch 40/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0357 - accuracy: 0.9975\n",
      "Epoch 41/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0334 - accuracy: 0.9975\n",
      "Epoch 42/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0308 - accuracy: 0.9975\n",
      "Epoch 43/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0282 - accuracy: 0.9975\n",
      "Epoch 44/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "400/400 [==============================] - 0s 59us/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "400/400 [==============================] - 0s 61us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "400/400 [==============================] - 0s 58us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "400/400 [==============================] - 0s 50us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 9.9754e-04 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 9.8459e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 9.7214e-04 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 9.6154e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19e4649b8c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=150, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:04:22.649727Z",
     "start_time": "2020-05-18T18:04:22.560916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda: 213.15%\n",
      "Acurácia: 75.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Perda: %.2f%%\" % (scores[0]*100))\n",
    "print(\"Acurácia: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:36:19.388817Z",
     "start_time": "2020-05-18T18:36:18.915100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(units=12, input_dim=84, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "\n",
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "\n",
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 12, input_dim=84, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:36:39.745777Z",
     "start_time": "2020-05-18T18:36:34.432406Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.6924 - precision: 0.6306\n",
      "Epoch 2/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.6883 - precision: 0.7113\n",
      "Epoch 3/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.6759 - precision: 0.7332\n",
      "Epoch 4/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.6401 - precision: 0.7370\n",
      "Epoch 5/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.5692 - precision: 0.7448\n",
      "Epoch 6/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.4749 - precision: 0.7499\n",
      "Epoch 7/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.4067 - precision: 0.7522\n",
      "Epoch 8/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.3652 - precision: 0.7609\n",
      "Epoch 9/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.3335 - precision: 0.7643\n",
      "Epoch 10/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.3073 - precision: 0.7715\n",
      "Epoch 11/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.2839 - precision: 0.7780\n",
      "Epoch 12/150\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.2617 - precision: 0.7845\n",
      "Epoch 13/150\n",
      "400/400 [==============================] - 0s 61us/step - loss: 0.2425 - precision: 0.7912\n",
      "Epoch 14/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.2243 - precision: 0.7969\n",
      "Epoch 15/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.2070 - precision: 0.8034\n",
      "Epoch 16/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.1895 - precision: 0.8086\n",
      "Epoch 17/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.1735 - precision: 0.8144\n",
      "Epoch 18/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.1577 - precision: 0.8204\n",
      "Epoch 19/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.1436 - precision: 0.8261\n",
      "Epoch 20/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.1308 - precision: 0.8306\n",
      "Epoch 21/150\n",
      "400/400 [==============================] - 0s 59us/step - loss: 0.1200 - precision: 0.8361\n",
      "Epoch 22/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.1101 - precision: 0.8404\n",
      "Epoch 23/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.1001 - precision: 0.8454\n",
      "Epoch 24/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0928 - precision: 0.8495\n",
      "Epoch 25/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0851 - precision: 0.8536\n",
      "Epoch 26/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0779 - precision: 0.8573\n",
      "Epoch 27/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0709 - precision: 0.8615\n",
      "Epoch 28/150\n",
      "400/400 [==============================] - 0s 61us/step - loss: 0.0645 - precision: 0.8649\n",
      "Epoch 29/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0596 - precision: 0.8682\n",
      "Epoch 30/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0545 - precision: 0.8718\n",
      "Epoch 31/150\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0505 - precision: 0.8752\n",
      "Epoch 32/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0474 - precision: 0.8783\n",
      "Epoch 33/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0443 - precision: 0.8812\n",
      "Epoch 34/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0416 - precision: 0.8843\n",
      "Epoch 35/150\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0388 - precision: 0.8868\n",
      "Epoch 36/150\n",
      "400/400 [==============================] - 0s 87us/step - loss: 0.0360 - precision: 0.8896\n",
      "Epoch 37/150\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0340 - precision: 0.8922\n",
      "Epoch 38/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0319 - precision: 0.8947\n",
      "Epoch 39/150\n",
      "400/400 [==============================] - 0s 77us/step - loss: 0.0301 - precision: 0.8971\n",
      "Epoch 40/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0284 - precision: 0.8995\n",
      "Epoch 41/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0273 - precision: 0.9016\n",
      "Epoch 42/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0253 - precision: 0.9038\n",
      "Epoch 43/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0240 - precision: 0.9058\n",
      "Epoch 44/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0225 - precision: 0.9078\n",
      "Epoch 45/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0213 - precision: 0.9097\n",
      "Epoch 46/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0204 - precision: 0.9116\n",
      "Epoch 47/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0196 - precision: 0.9134\n",
      "Epoch 48/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0188 - precision: 0.9151\n",
      "Epoch 49/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0179 - precision: 0.9168\n",
      "Epoch 50/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0170 - precision: 0.9184\n",
      "Epoch 51/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0165 - precision: 0.9199\n",
      "Epoch 52/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0159 - precision: 0.9214\n",
      "Epoch 53/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0155 - precision: 0.9228\n",
      "Epoch 54/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0151 - precision: 0.9241\n",
      "Epoch 55/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0147 - precision: 0.9255\n",
      "Epoch 56/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0143 - precision: 0.9268\n",
      "Epoch 57/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0140 - precision: 0.9280\n",
      "Epoch 58/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0137 - precision: 0.9292\n",
      "Epoch 59/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0135 - precision: 0.9304\n",
      "Epoch 60/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0132 - precision: 0.9315\n",
      "Epoch 61/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0130 - precision: 0.9326\n",
      "Epoch 62/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0127 - precision: 0.9336\n",
      "Epoch 63/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0126 - precision: 0.9346\n",
      "Epoch 64/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0124 - precision: 0.9356\n",
      "Epoch 65/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0122 - precision: 0.9366\n",
      "Epoch 66/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0120 - precision: 0.9375\n",
      "Epoch 67/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0119 - precision: 0.9384\n",
      "Epoch 68/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0117 - precision: 0.9393\n",
      "Epoch 69/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0116 - precision: 0.9401\n",
      "Epoch 70/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0115 - precision: 0.9409\n",
      "Epoch 71/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0114 - precision: 0.9418\n",
      "Epoch 72/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0113 - precision: 0.9426\n",
      "Epoch 73/150\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0112 - precision: 0.9433\n",
      "Epoch 74/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0111 - precision: 0.9441\n",
      "Epoch 75/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0110 - precision: 0.9448\n",
      "Epoch 76/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0108 - precision: 0.9455\n",
      "Epoch 77/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0108 - precision: 0.9462\n",
      "Epoch 78/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0107 - precision: 0.9468\n",
      "Epoch 79/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0106 - precision: 0.9475\n",
      "Epoch 80/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0105 - precision: 0.9481\n",
      "Epoch 81/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0105 - precision: 0.9488\n",
      "Epoch 82/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0104 - precision: 0.9494\n",
      "Epoch 83/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0103 - precision: 0.9500\n",
      "Epoch 84/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0103 - precision: 0.9505\n",
      "Epoch 85/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0102 - precision: 0.9511\n",
      "Epoch 86/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0101 - precision: 0.9517\n",
      "Epoch 87/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0101 - precision: 0.9522\n",
      "Epoch 88/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0101 - precision: 0.9527\n",
      "Epoch 89/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0100 - precision: 0.9532\n",
      "Epoch 90/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0099 - precision: 0.9538\n",
      "Epoch 91/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0100 - precision: 0.9543\n",
      "Epoch 92/150\n",
      "400/400 [==============================] - 0s 59us/step - loss: 0.0099 - precision: 0.9547\n",
      "Epoch 93/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0099 - precision: 0.9552\n",
      "Epoch 94/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0098 - precision: 0.9557\n",
      "Epoch 95/150\n",
      "400/400 [==============================] - 0s 52us/step - loss: 0.0098 - precision: 0.9561\n",
      "Epoch 96/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0098 - precision: 0.9566\n",
      "Epoch 97/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0097 - precision: 0.9570\n",
      "Epoch 98/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0097 - precision: 0.9574\n",
      "Epoch 99/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0096 - precision: 0.9579\n",
      "Epoch 100/150\n",
      "400/400 [==============================] - 0s 58us/step - loss: 0.0096 - precision: 0.9583\n",
      "Epoch 101/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0096 - precision: 0.9587\n",
      "Epoch 102/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0095 - precision: 0.9591\n",
      "Epoch 103/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0095 - precision: 0.9595\n",
      "Epoch 104/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0095 - precision: 0.9598\n",
      "Epoch 105/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0095 - precision: 0.9602\n",
      "Epoch 106/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0095 - precision: 0.9606\n",
      "Epoch 107/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0094 - precision: 0.9610\n",
      "Epoch 108/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0094 - precision: 0.9613\n",
      "Epoch 109/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0094 - precision: 0.9617\n",
      "Epoch 110/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0094 - precision: 0.9620\n",
      "Epoch 111/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0093 - precision: 0.9623\n",
      "Epoch 112/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0093 - precision: 0.9627\n",
      "Epoch 113/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0093 - precision: 0.9630\n",
      "Epoch 114/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0093 - precision: 0.9633\n",
      "Epoch 115/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0093 - precision: 0.9636\n",
      "Epoch 116/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0093 - precision: 0.9639\n",
      "Epoch 117/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0093 - precision: 0.9642\n",
      "Epoch 118/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0092 - precision: 0.9645\n",
      "Epoch 119/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0092 - precision: 0.9648\n",
      "Epoch 120/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0092 - precision: 0.9651\n",
      "Epoch 121/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0092 - precision: 0.9654\n",
      "Epoch 122/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0092 - precision: 0.9657\n",
      "Epoch 123/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0092 - precision: 0.9659\n",
      "Epoch 124/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0092 - precision: 0.9662\n",
      "Epoch 125/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0092 - precision: 0.9665\n",
      "Epoch 126/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0091 - precision: 0.9667\n",
      "Epoch 127/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0091 - precision: 0.9670\n",
      "Epoch 128/150\n",
      "400/400 [==============================] - 0s 65us/step - loss: 0.0091 - precision: 0.9672\n",
      "Epoch 129/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0091 - precision: 0.9675\n",
      "Epoch 130/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0091 - precision: 0.9677\n",
      "Epoch 131/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0091 - precision: 0.9680\n",
      "Epoch 132/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0091 - precision: 0.9682\n",
      "Epoch 133/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0091 - precision: 0.9685\n",
      "Epoch 134/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0091 - precision: 0.9687\n",
      "Epoch 135/150\n",
      "400/400 [==============================] - 0s 57us/step - loss: 0.0091 - precision: 0.9689\n",
      "Epoch 136/150\n",
      "400/400 [==============================] - 0s 55us/step - loss: 0.0091 - precision: 0.9691\n",
      "Epoch 137/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0091 - precision: 0.9694\n",
      "Epoch 138/150\n",
      "400/400 [==============================] - 0s 62us/step - loss: 0.0090 - precision: 0.9696\n",
      "Epoch 139/150\n",
      "400/400 [==============================] - 0s 80us/step - loss: 0.0090 - precision: 0.9698\n",
      "Epoch 140/150\n",
      "400/400 [==============================] - 0s 72us/step - loss: 0.0090 - precision: 0.9700\n",
      "Epoch 141/150\n",
      "400/400 [==============================] - 0s 74us/step - loss: 0.0090 - precision: 0.9702\n",
      "Epoch 142/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0090 - precision: 0.9704\n",
      "Epoch 143/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0090 - precision: 0.9706\n",
      "Epoch 144/150\n",
      "400/400 [==============================] - 0s 70us/step - loss: 0.0090 - precision: 0.9708\n",
      "Epoch 145/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0090 - precision: 0.9710\n",
      "Epoch 146/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0090 - precision: 0.9712\n",
      "Epoch 147/150\n",
      "400/400 [==============================] - 0s 75us/step - loss: 0.0090 - precision: 0.9714\n",
      "Epoch 148/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0090 - precision: 0.9716\n",
      "Epoch 149/150\n",
      "400/400 [==============================] - 0s 67us/step - loss: 0.0090 - precision: 0.9718\n",
      "Epoch 150/150\n",
      "400/400 [==============================] - 0s 60us/step - loss: 0.0090 - precision: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19e46f345c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=150, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:49:27.361357Z",
     "start_time": "2020-05-18T18:49:27.351361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda: 200.18%\n",
      "Precisão: 97.03%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Perda: %.2f%%\" % (results[0]*100))\n",
    "print(\"Precisão: %.2f%%\" % (results[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
